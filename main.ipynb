{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7907b832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './src')  # 或者绝对路径：/full/path/to/your_project\n",
    "from src.xmcdata import *\n",
    "from gen_model import *\n",
    "from verbalizer import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f0571d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./xmc-base/\"\n",
    "dataset_name = \"eurlex-4k/\"\n",
    "data_dir = data_dir + dataset_name\n",
    "model_names = [\n",
    "        \"google/flan-t5-base\",  # T5-base\n",
    "        \"google/flan-t5-large\",  # T5-large\n",
    "        \"google/flan-t5-xl\",     # T5-xl\n",
    "        \"facebook/bart-base\",    # BART\n",
    "        \"google/pegasus-xsum\"    # Pegasus\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7afca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9d5af5493e4122b036fe48ebe4d50d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bbf1eda2854ba7ad9162f36be066f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da423f3ad0364e998ca532c51e1b43b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11a11f0e9dd4b3e8b5ecf9269452521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d2ec0ee3fd43eabd1a9b42656cc43d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a80593f12e4ca3bf89ff60d36a3d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa799e64edd4c56a1167a4650de4be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f660b5380fb245c3921ad77436bffd48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d01441de0343bf9456881d452fc628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d33aae50964a3688b9ce45e8570268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e397ec8d35b54676b130e3dc8cd945ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标签库大小: 3956\n",
      "使用模型: all-MiniLM-L6-v2\n",
      "计算标签库embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38747b00e3b84c769426b745aaf28335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标签库embeddings计算完成!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理标签列表: 100%|██████████| 3865/3865 [00:22<00:00, 172.55it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "label_map = load_label_text_map(data_dir+\"output-items.txt\")\n",
    "\n",
    "label_map = [v for k, v in sorted(label_map.items(), key=lambda x: x[0])]\n",
    "\n",
    "pred_label_list = []\n",
    "with open(data_dir+\"gen_pred_\"+model_names[1].split(\"/\")[-1]+\".txt\",\"r\") as r:\n",
    "    for i in r:\n",
    "        pred_label_list.append(i.strip(\".\").split(\",\"))\n",
    "replacer = LabelReplacementSystem(label_map,model_name='all-MiniLM-L6-v2')\n",
    "replaced_result = replacer.replace_batch(pred_label_list)\n",
    "final_labels = [result['final'] for result in replaced_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17708657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_lists_processed': 3865,\n",
       " 'total_labels_original': 19216,\n",
       " 'total_labels_after_dedup': 19099,\n",
       " 'deduplication_reduction': '0.6%',\n",
       " 'total_replacements_made': 4332,\n",
       " 'total_kept_from_library': 14767,\n",
       " 'replacement_rate': '22.7%',\n",
       " 'avg_similarity_score': '0.919',\n",
       " 'min_similarity_score': '0.401',\n",
       " 'max_similarity_score': '0.993'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacer.get_summary_stats(replaced_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f89b90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir+\"test_replaced.txt\", \"w\")as w:\n",
    "    for i in final_labels:\n",
    "        w.write(\",\".join(i)+\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82c4dba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded T5 tokenizer: google/flan-t5-large\n",
      "Loading T5 model: google/flan-t5-large\n",
      "Model loaded on cuda\n",
      "Model type: T5\n",
      "Model parameters: 783,150,080\n",
      "Loading local model from ./xmc-base/eurlex-4k//outputs/flan-t5-large...\n",
      "Local model loaded successfully from ./xmc-base/eurlex-4k//outputs/flan-t5-large\n"
     ]
    }
   ],
   "source": [
    "t5_config = T2TConfig(\n",
    "        model_name=model_names[1],  # Change to other   models as needed\n",
    "        dataset_dir=data_dir,\n",
    "        output_dir=data_dir+\"/outputs/\"+model_names[1].split(\"/\")[-1],\n",
    "        prompt=\"Summarize this document by unstemmed keyphrases:\",\n",
    "        #task_prefix=\"classify:\",  # T5-style task  prefix\n",
    "        num_epochs=5,\n",
    "        batch_size=4, # base-16, large-4, xl-2? for    24GB\n",
    "        learning_rate= 2e-5,\n",
    "        max_input_length=512,\n",
    "        max_output_length=128,\n",
    "        strict_tokenization=True,\n",
    "        fp16=False, #t5 cannot use fp16\n",
    "        bf16= True,\n",
    "    )\n",
    "model = UniversalT2TModel(t5_config)\n",
    "model.load_local_model(model_path=data_dir+\"/outputs/\"+model_names[1].split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec1c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenized data from cache:./xmc-base/eurlex-4k//train.pt\n",
      "Loaded 15449 samples from cache\n",
      "Loading tokenized data from cache:./xmc-base/eurlex-4k//test.pt\n",
      "Loaded 3865 samples from cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating with T5 Standards:  54%|█████▍    | 2083/3863 [36:23<31:45,  1.07s/it]  "
     ]
    }
   ],
   "source": [
    "model.predict_train_set(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0305a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ranker import *\n",
    "ranker = DocumentLabelRanker()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
